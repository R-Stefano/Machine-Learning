{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep neural network using tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial I want to implement a DNN that I explained **here** using tensorflow. Tensorflow is a framework (In really simply words: a bunch of commands to quickly write programs for deep learning) a lot used these days. So what a best opportunity to grasp the basic directly in a project. **here** a cheatsheet for tensorflow.\n",
    "\n",
    "Let's use the same dataset used for logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3       4       5       6      7   8\n",
       "0  M  0.455  0.365  0.095  0.5140  0.2245  0.1010  0.150  15\n",
       "1  M  0.350  0.265  0.090  0.2255  0.0995  0.0485  0.070   7\n",
       "2  F  0.530  0.420  0.135  0.6770  0.2565  0.1415  0.210   9\n",
       "3  M  0.440  0.365  0.125  0.5160  0.2155  0.1140  0.155  10\n",
       "4  I  0.330  0.255  0.080  0.2050  0.0895  0.0395  0.055   7"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "db=pd.read_csv(\"abalone.data\", header=None)\n",
    "db.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to classify based on the information in the database (columns 1-8) if the abalone if Male, Female or Infant (column 0). So let's split the database in examples and labels. Convert them to mnumpy vector/matrix in order to iterate through them and then encode every element in the label vector as a 3-element (k=3) vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples shape: (4177, 8)\n",
      "Labels shape: (4177, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "labels=db[0].as_matrix()\n",
    "examples=db.drop(0, axis=1).as_matrix()\n",
    "zeros=np.zeros((labels.shape[0],3))\n",
    "\n",
    "#encode the labels\n",
    "for idx, item in enumerate(labels):\n",
    "    if item=='I':\n",
    "        zeros[idx]=np.array([1,0,0])\n",
    "    elif item=='M':\n",
    "        zeros[idx]=np.array([0,1,0])\n",
    "    else:\n",
    "        zeros[idx]=np.array([0,0,1])\n",
    "labels=zeros\n",
    "print(\"Examples shape:\", examples.shape)\n",
    "print(\"Labels shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing to do before define the graph is shuffle the examples and then split the dataset in train and test examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train examples shape: (2923, 8)\n",
      "Test examples shape: (1254, 8)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(examples, labels, test_size=0.3, shuffle=True)\n",
    "print(\"Train examples shape:\", x_train.shape)\n",
    "print(\"Test examples shape:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define the number of layers and the number of neurons that our model is going to have. First of all, we have examples with **8 features** (8 columns), so the **input layer** is going to have 8 neurons. Secondly, every label example is a 3-dimensional vector (k=3), so the **output layer** is going to have k neurons. In other words, **3 neurons**. Now we have to define how many hidden layers (I'm thinking 3 to keep it easy) and how many neurons for each hidden layer (I'm thinking 20, 30, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#input layer (8 neurons)\n",
    "examples=tf.placeholder(tf.float32, shape=[None,8])\n",
    "\n",
    "#first hidden layer (variables initialized with uniform distribution)\n",
    "w1=tf.get_variable(\"h1_weights\", [8,20])\n",
    "b1=tf.get_variable(\"h1_biases\", [20])\n",
    "logit1=tf.add(tf.matmul(examples,w1), b1)\n",
    "output1=tf.sigmoid(logit1) #output1 is a [N,20] matrix\n",
    "\n",
    "#second hidden layer (variables initialized with a gaussian distribution )\n",
    "initW2=tf.random_normal((20,30), mean=0, stddev=1)\n",
    "initB2=tf.random_normal((1,30), mean=0, stddev=1)\n",
    "w2=tf.get_variable(\"h2_weights\", initializer=initW2)\n",
    "b2=tf.get_variable(\"h2_biases\", initializer=initB2)\n",
    "logit2=tf.add(tf.matmul(output1,w2), b2)\n",
    "output2=tf.sigmoid(logit2) #output2 is a [N,200] matrix\n",
    "\n",
    "#third hidden layer\n",
    "initW3=tf.random_normal((30,40), mean=0, stddev=1)\n",
    "initB3=tf.random_normal((1,40), mean=0, stddev=1)\n",
    "w3=tf.get_variable(\"h3_weights\", initializer=initW3)\n",
    "b3=tf.get_variable(\"h3_biases\", initializer=initB3)\n",
    "logit3=tf.add(tf.matmul(output2,w3), b3)\n",
    "output3=tf.sigmoid(logit3) #output3 is a [N,40] matrix\n",
    "\n",
    "#output layer(3 neurons)\n",
    "initWOut=tf.random_normal((40,3), mean=0, stddev=1)\n",
    "initBOut=tf.random_normal((1,3), mean=0, stddev=1)\n",
    "wout=tf.get_variable(\"out_weights\", initializer=initWOut)\n",
    "bout=tf.get_variable(\"out_biases\", initializer=initBOut)\n",
    "logitout=tf.add(tf.matmul(output3,wout),bout)\n",
    "output=tf.nn.softmax(logitout)\n",
    "\n",
    "#placeholder to feed the labels\n",
    "labels=tf.placeholder(tf.float32, shape=[None,3])\n",
    "\n",
    "#calculate cost (I added 1e-9=0.000000001) to avoid log(0)=infinity\n",
    "exampleError=-tf.reduce_sum(labels * tf.log(output + 1e-9)+ (1-labels) * tf.log(1-output+ 1e-9), 1)\n",
    "error=tf.reduce_mean(exampleError,0)\n",
    "\n",
    "#define optimizer for backpropragation\n",
    "learning_rate=0.0001\n",
    "opt=tf.train.GradientDescentOptimizer(learning_rate)\n",
    "gradient=opt.minimize(error)\n",
    "\n",
    "#define the operation to meausure the accuracy\n",
    "#for every example's output vector, return the index of highest value, if it match the index of the result\n",
    "#return 1 (correct prediction) else 0\n",
    "pred=tf.equal(tf.argmax(labels,1), tf.argmax(output,1))\n",
    "#calculate over all the examples, how many are 1, more ones, more correct prediction, more accuracy!\n",
    "accuracy=tf.reduce_mean(tf.cast(pred, tf.float32)) #it is a number between 0-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before run the graph, I'm going to define a series of statement that we are going to use later to show the value of different variables such as the distribution of weights, the error and the distribution of the output in each layer using **tensorboard**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'accuracy:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.summary.histogram('h1_weight', w1)\n",
    "tf.summary.histogram('h1_output', output1)\n",
    "tf.summary.histogram('h2_weight', w2)\n",
    "tf.summary.histogram('h2_output', output2)\n",
    "tf.summary.histogram('h3_weight', w3)\n",
    "tf.summary.histogram('h3_output', output3)\n",
    "tf.summary.histogram('output_weight', wout)\n",
    "tf.summary.histogram('output', output)\n",
    "\n",
    "tf.summary.scalar('error', error)\n",
    "tf.summary.scalar('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have defined the graph, we have to:\n",
    "initialize the variables,\n",
    "group the summaries defined above and\n",
    "save the graph structure and the values inside the graph (weight, biases, error.. values) on a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "init=tf.global_variables_initializer()\n",
    "summ=tf.summary.merge_all()\n",
    "file=tf.summary.FileWriter('summaries/', sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have to define define epoches and batches and then we can run the graph!\n",
    "\n",
    "We devide the train dataset in batches of 100 examples. We are going to feed 100 examples each time instead of all togheter to lighten the computational power required. We start with the first 100 examples (from 0 to 99) and we say to tensorflow, pass the first 100 examples x_train\\[batch_start:batch_end\\] through the placeholder named `example` and the first 100 y_train labels through the placeholder `labels`.\n",
    "The next line ask to compute the variables gradient and error defined before. The variables gradient will update the weights, while the variable error we are going to use it to see how the error is changing through time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Error 111.56911993026733 | Accuracy 0.32535884\n",
      "Epoch 50 | Error 78.18855547904968 | Accuracy 0.13716109\n",
      "Epoch 100 | Error 59.14495897293091 | Accuracy 0.14593302\n",
      "Epoch 150 | Error 55.31067454814911 | Accuracy 0.3676236\n",
      "Epoch 200 | Error 55.01319134235382 | Accuracy 0.42424244\n",
      "Epoch 250 | Error 54.83446550369263 | Accuracy 0.47767144\n",
      "Epoch 300 | Error 54.661794781684875 | Accuracy 0.4952153\n",
      "Epoch 350 | Error 54.49092781543732 | Accuracy 0.5\n",
      "Epoch 400 | Error 54.32077193260193 | Accuracy 0.50717705\n",
      "Epoch 450 | Error 54.15148341655731 | Accuracy 0.52073365\n",
      "Epoch 500 | Error 53.983920216560364 | Accuracy 0.5350877\n",
      "Epoch 550 | Error 53.819246768951416 | Accuracy 0.53748006\n",
      "Epoch 600 | Error 53.658419370651245 | Accuracy 0.5366826\n",
      "Epoch 650 | Error 53.501829385757446 | Accuracy 0.5334928\n",
      "Epoch 700 | Error 53.34944772720337 | Accuracy 0.52870816\n",
      "Epoch 750 | Error 53.20088732242584 | Accuracy 0.52711326\n",
      "Epoch 800 | Error 53.05561935901642 | Accuracy 0.52551836\n",
      "Epoch 850 | Error 52.9132741689682 | Accuracy 0.5263158\n",
      "Epoch 900 | Error 52.77357065677643 | Accuracy 0.5247209\n",
      "Epoch 950 | Error 52.63625717163086 | Accuracy 0.52232856\n",
      "Training finished!\n"
     ]
    }
   ],
   "source": [
    "N=x_train.shape[0] #take number of examples in the train dataset\n",
    "epoches=1000\n",
    "batches=int(N/100) #100 examples in each batch\n",
    "\n",
    "#run the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(epoches):\n",
    "        batch_start=0\n",
    "        batch_end=100\n",
    "        ep_error=0 #error for the epoch\n",
    "        for batch in range(batches):\n",
    "            feed={examples:x_train[batch_start:batch_end], labels:y_train[batch_start:batch_end]}\n",
    "            #ask to compute the gradient and error variables\n",
    "            _,err=sess.run([gradient,error], feed_dict=feed)\n",
    "            batch_start+=100\n",
    "            batch_end +=100\n",
    "            ep_error+=err #error for the batch\n",
    "\n",
    "        if epoch%10==0:\n",
    "            feed={examples:x_test, labels:y_test}\n",
    "            acc, summary=sess.run([accuracy,summ], feed)\n",
    "            #add the values of the graph to the file and assign it to their epoch\n",
    "            file.add_summary(summary, epoch)\n",
    "\n",
    "        if epoch%50==0:\n",
    "            print(\"Epoch\",epoch,\"| Error\", ep_error, \"| Accuracy\", acc)\n",
    "\n",
    "print(\"Training finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every 10 epochs we are going to compute the accuracy and save the values of the graph on the file that we subsequently access to print the data on tensorboard using the command `tensorboard --logdir=path/summaries` and then open the broswer and type `localhost/portNumber`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
